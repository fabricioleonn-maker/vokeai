/**
 * LLM Service - Centralized AI processing for all agents
 */

export interface LLMMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface LLMResponse {
  content: string;
  usage?: {
    prompt_tokens?: number;
    completion_tokens?: number;
    total_tokens: number;
  };
}

export interface AgentPromptConfig {
  systemPrompt: string;
  conversationHistory: LLMMessage[];
  tenantContext?: {
    name: string;
    plan: string;
    customInstructions?: string;
  };
  agentConfig?: {
    tone?: 'formal' | 'neutral' | 'casual' | 'friendly';
    language?: string;
    maxTokens?: number;
    model?: string;
    tier?: 'lite' | 'advanced';
    temperature?: number;
  };
}

/**
 * Call LLM API with configured prompts
 */
export async function callLLM(config: AgentPromptConfig): Promise<LLMResponse> {
  const OLLAMA_URL = process.env.OLLAMA_BASE_URL || 'http://127.0.0.1:11434';
  const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
  const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

  // Configura√ß√£o de Provider (Auto-detect logic)
  let PROVIDER = process.env.LLM_PROVIDER;

  if (!PROVIDER) {
    if (GEMINI_API_KEY) {
      PROVIDER = 'gemini';
    } else if (OPENAI_API_KEY) {
      PROVIDER = 'openai';
    } else {
      PROVIDER = 'ollama'; // Default fallback only if no keys present
    }
  }

  // Debug provider selection (server-side log)
  console.log(`ü§ñ LLM Service using Provider: ${PROVIDER}`);


  // Build full system prompt
  let fullSystemPrompt = config.systemPrompt;

  if (config.tenantContext) {
    fullSystemPrompt += `\n\n## Contexto do Cliente\n`;
    fullSystemPrompt += `- Empresa: ${config.tenantContext.name}\n`;
    fullSystemPrompt += `- Plano: ${config.tenantContext.plan}\n`;
    if (config.tenantContext.customInstructions) {
      fullSystemPrompt += `\n## Instru√ß√µes Personalizadas\n${config.tenantContext.customInstructions}`;
    }
  }

  // Tone handling
  if (config.agentConfig?.tone) {
    const toneMap = {
      formal: 'Use linguagem formal e profissional.',
      neutral: 'Use linguagem neutra e acess√≠vel.',
      casual: 'Use linguagem casual e amig√°vel, pode usar emojis.',
      friendly: 'Use linguagem calorosa e pr√≥xima, como um amigo que entende do assunto. Pode usar emojis com modera√ß√£o.'
    };
    fullSystemPrompt += `\n\n## Tom de Voz\n${toneMap[config.agentConfig.tone]}`;
  }

  const messages: LLMMessage[] = [
    { role: 'system', content: fullSystemPrompt },
    ...config.conversationHistory
  ];

  try {
    // üü¢ PROVIDER: OLLAMA (LOCAL)
    if (PROVIDER === 'ollama') {
      console.log('ü¶ô Usando Ollama Local:', OLLAMA_URL);
      const response = await fetch(`${OLLAMA_URL}/api/chat`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: 'llama3', // Ou 'mistral', 'gemma'
          messages: messages,
          stream: false,
          options: {
            temperature: 0.7,
            num_ctx: 4096
          }
        })
      });

      if (!response.ok) throw new Error(`Ollama Error: ${response.status}`);
      const data = await response.json();
      return {
        content: data.message?.content || '',
        usage: {
          prompt_tokens: data.prompt_eval_count || 0,
          completion_tokens: data.eval_count || 0,
          total_tokens: (data.prompt_eval_count || 0) + (data.eval_count || 0)
        }
      };
    }

    // üîµ PROVIDER: GEMINI (GOOGLE)
    if (PROVIDER === 'gemini') {
      if (!GEMINI_API_KEY) throw new Error('GEMINI_API_KEY n√£o configurada');

      // Gemini API structure is different, using simple fetch adapter here for OpenAI-compat endpoint
      // Or standard Gemini REST API
      const GEMINI_URL = `https://generativelanguage.googleapis.com/v1/models/gemini-2.5-flash-lite:generateContent?key=${GEMINI_API_KEY}`;

      const geminiContents = messages.map(m => ({
        role: m.role === 'user' ? 'user' : 'model',
        parts: [{ text: m.content }]
      }));

      // Adjust system prompt for Gemini (it prefers system instructions separately or merged)
      // Simple merge for now:
      if (messages[0].role === 'system') {
        geminiContents[0] = { role: 'user', parts: [{ text: `SYSTEM INSTRUCTION: ${messages[0].content}` }] };
      }

      const response = await fetch(GEMINI_URL, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contents: geminiContents,
          generationConfig: {
            temperature: 0.7,
            maxOutputTokens: config.agentConfig?.maxTokens || 1500
          }
        })
      });

      if (!response.ok) {
        const err = await response.text();
        throw new Error(`Gemini Error: ${err}`);
      }

      const data = await response.json();
      return {
        content: data.candidates?.[0]?.content?.parts?.[0]?.text || '',
        usage: { total_tokens: 0 } // Gemini doesn't always return usage in this endpoint format simply
      };
    }

    // üî¥ DEFAULT: OPENAI (STANDARD)
    if (PROVIDER === 'openai' || (!PROVIDER && OPENAI_API_KEY)) {
      if (!OPENAI_API_KEY) throw new Error('OPENAI_API_KEY not configured');

      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${OPENAI_API_KEY}`
        },
        body: JSON.stringify({
          model: config.agentConfig?.model ||
            (config.agentConfig?.tier === 'advanced' ? 'gpt-4o' : 'gpt-4o-mini'),
          messages,
          max_tokens: config.agentConfig?.maxTokens || 1500,
          temperature: config.agentConfig?.temperature ?? 0.7,
        })
      });

      if (!response.ok) {
        const error = await response.text();
        console.error('OpenAI API error:', error);
        throw new Error(`OpenAI API error: ${response.status}`);
      }

      const data = await response.json();
      return {
        content: data.choices?.[0]?.message?.content || '',
        usage: data.usage
      };
    }

    throw new Error(`Provider ${PROVIDER} not supported or configured correctly.`);

  } catch (error) {
    console.error('LLM call failed:', error);
    throw error;
  }
}

/**
 * Get conversation history from database
 */
export async function getConversationHistory(
  conversationId: string,
  limit: number = 10
): Promise<LLMMessage[]> {
  const { prisma } = await import('@/lib/db');

  const turns = await prisma.conversationTurn.findMany({
    where: { conversationId },
    orderBy: { createdAt: 'desc' },
    take: limit
  });

  // Reverse to get chronological order
  return turns.reverse().map((turn: any) => ({
    role: turn.role as 'user' | 'assistant',
    content: turn.content
  }));
}

/**
 * Pre-built agent system prompts
 */
export const AGENT_PROMPTS = {
  orchestrator: `Voc√™ √© o orquestrador inteligente do Voke AI.
Sua fun√ß√£o √©:
1. Entender a inten√ß√£o do usu√°rio
2. Direcionar para o agente especializado correto
3. Manter o contexto da conversa
4. Garantir uma experi√™ncia fluida

Agentes dispon√≠veis:
- Secret√°ria Virtual: agendamentos, calend√°rio, lembretes
- Financeiro: saldos, transa√ß√µes, cobran√ßas, pagamentos
- Atendimento N1: d√∫vidas gerais, FAQs, suporte b√°sico
- Vendas: planos, pre√ßos, upgrade, demonstra√ß√µes
- Produtividade: emails, planilhas, apresenta√ß√µes, checklists

Responda de forma natural e humanizada. Identifique a necessidade e direcione adequadamente.`,

  secretary: `Voc√™ √© a Secret√°ria Virtual do Voke AI.

## Suas Capacidades
- Agendar reuni√µes e compromissos
- Consultar disponibilidade de hor√°rios
- Enviar lembretes e confirma√ß√µes
- Gerenciar calend√°rio
- Remarcar ou cancelar eventos

## Comportamento
- Seja proativa e organizada
- Sempre confirme data, hora e participantes
- Sugira hor√°rios alternativos quando necess√°rio
- Use linguagem profissional mas acolhedora

## Fluxo de Agendamento
1. Entender o tipo de evento
2. Perguntar data e hor√°rio preferido
3. Verificar disponibilidade (simule se necess√°rio)
4. Confirmar todos os detalhes
5. Pedir confirma√ß√£o final antes de agendar`,

  finance: `Voc√™ √© o Agente Financeiro do Voke AI.

## Suas Capacidades
- Consultar saldos e extratos
- Informar sobre transa√ß√µes
- Ajudar com cobran√ßas e pagamentos
- Gerar boletos e links de pagamento
- Analisar fluxo de caixa

## Comportamento
- Seja preciso com n√∫meros e valores
- Sempre confirme opera√ß√µes financeiras
- Explique taxas e condi√ß√µes claramente
- Mantenha confidencialidade

## Seguran√ßa
- N√£o execute transa√ß√µes sem confirma√ß√£o expl√≠cita
- Para opera√ß√µes sens√≠veis, solicite verifica√ß√£o adicional
- Sempre informe o que ser√° feito antes de executar`,

  support: `Voc√™ √© o Agente de Atendimento N1 do Voke AI.

## Suas Capacidades
- Responder d√∫vidas frequentes
- Resolver problemas b√°sicos
- Fornecer informa√ß√µes sobre o sistema
- Triagem de solicita√ß√µes
- Escalar para especialistas quando necess√°rio

## Comportamento
- Seja emp√°tico e paciente
- Fa√ßa perguntas para entender melhor o problema
- Ofere√ßa solu√ß√µes passo a passo
- Se n√£o souber resolver, encaminhe para o agente correto

## Handoff
- Detecte interesse comercial ‚Üí transfira para Vendas
- Problemas t√©cnicos complexos ‚Üí transfira para Suporte T√©cnico
- Quest√µes financeiras ‚Üí transfira para Financeiro`,

  sales: `Voc√™ √© o Agente de Vendas do Voke AI.

## Suas Capacidades
- Apresentar planos e pre√ßos
- Qualificar leads
- Lidar com obje√ß√µes
- Oferecer trials e demonstra√ß√µes
- Fechar vendas

## Planos Dispon√≠veis
- Free: B√°sico, 1 agente, 100 mensagens/m√™s
- Basic (R$49/m√™s): 3 agentes, 1.000 mensagens, suporte email
- Pro (R$149/m√™s): 5 agentes, ilimitado, integra√ß√µes, suporte priorit√°rio

## T√©cnicas de Venda
- Entenda a dor do cliente primeiro
- Demonstre valor antes de pre√ßo
- Use casos de sucesso
- Ofere√ßa garantia de satisfa√ß√£o

## Obje√ß√µes Comuns
- "Est√° caro" ‚Üí Mostre ROI e economia de tempo
- "Preciso pensar" ‚Üí Ofere√ßa trial gratuito
- "J√° uso outro" ‚Üí Compare benef√≠cios √∫nicos`,

  productivity: `Voc√™ √© o Agente de Produtividade do Voke AI.

## Suas Capacidades
- Redigir emails profissionais
- Criar estruturas de planilhas
- Montar apresenta√ß√µes
- Gerar checklists e listas de tarefas
- Resumir documentos

## Comportamento
- Pergunte sobre o contexto e objetivo
- Ofere√ßa op√ß√µes de tom (formal/casual)
- Entregue conte√∫do formatado e pronto para uso
- Sugira melhorias quando apropriado

## Formatos de Sa√≠da
- Emails: Assunto + Corpo formatado
- Planilhas: Colunas + Exemplo de dados
- Apresenta√ß√µes: Slides com t√≠tulos e bullets
- Checklists: Itens numerados com descri√ß√µes`
};
